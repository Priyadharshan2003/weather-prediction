{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "2KARIMNAGAR_COORDS = (17.3850, 78.4867)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# url = \"https://power.larc.nasa.gov/api/temporal/daily/point?parameters=CLOUD_AMT&community=SB&longitude=79.1288&latitude=18.4386&start=20170101&end=20170201&format=JSON\"\n",
    "url =  \"https://power.larc.nasa.gov/api/temporal/daily/point\"\n",
    "\n",
    "'''\n",
    "We are going to retrieve the following from the \n",
    "'''\n",
    "params = {\n",
    "    \"parameters\":'T,RH,WS,MIDDAY_INSOL,PRECIPITATIONCAL,GW,CLOUD_AMT,',\n",
    "    \"start\": \"20190101\",\n",
    "    \"end\": \"20191231\",\n",
    "    \"community\": \"AG\",\n",
    "    \"latitude\": str(2KARIMNAGAR_COORDS[0]),\n",
    "    \"longitude\": str(2KARIMNAGAR_COORDS[1]),\n",
    "    \"format\":\"JSON\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def parse_MEI_data(filepath:str):\n",
    "    with open(file=filepath) as data_file:\n",
    "        data = {}\n",
    "        for line in data_file.readlines()[1:]:\n",
    "            # print(line)\n",
    "            line = line.split()\n",
    "            # print(line)\n",
    "            data[line[0]] = line[1:]\n",
    "        # print(data)\n",
    "        return pd.DataFrame().from_dict(data, orient='Index')\n",
    "\n",
    "parse_MODEL_DATA(r'data\\Classified_worlddata\\MODEL.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_MJO_data(filepath: str):\n",
    "    with open(file=filepath) as data_file:\n",
    "        data = {}\n",
    "        for index, line in enumerate(data_file.readlines()[1:]):\n",
    "            line = line.split()\n",
    "            date = str(''.join([line[0], f'{int(line[1]):02d}', f'{int(line[2]):02d}']))\n",
    "            data[index] = [int(date),*line[4:]]\n",
    "        # return pd.DataFrame(data)\n",
    "        # print(data)\n",
    "    df = pd.DataFrame().from_dict(data=data, orient='Index', columns=['date','PC1','PC2','amplitude']) \n",
    "    return df\n",
    "parse_MAJOR_DATA(\"data\\Classified_worlddata\\MAJOR_DATA.txt\").dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'data\\Classified_Distdata\\1adilabad.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(parse_MAJOR_DATA(\"data\\Classified_worlddata\\MAJOR_DATA.txt\"), on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.date\n",
    "MODEL_data = parse_MAJOR_DATA('data\\Classified_worlddata\\MODEL.txt')\n",
    "x.apply(lambda x: MAJOR_DATA.loc[str(x)[:4]][int(str(x)[4:6]) - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets():\n",
    "    df = pd.read_csv(r'data\\Classified_Distdata\\1adilabad_nasa_data.csv')\n",
    "    MODEL_data = parse_MODEL_data('data\\Classified_worlddata\\MODEL.txt')\n",
    "    MAJOR_DATA = parse_MAJOR_DATA('data\\Classified_worlddata\\MAJOR_DATA.txt')\n",
    "    \n",
    "    df['MODEL'] = df.date.apply(lambda x: MODEL_data.loc[str(x)[:4]][int(str(x)[4:6]) - 1]) # Find the correspoding value based on the date and month. \n",
    "    temp = df.merge(MAJOR_DATA, on='date', how='left')\n",
    "    return temp\n",
    "create_datasets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f157a749752437ddb720be10484a0c4635006bd7042b904d6d9e87d41ece340"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
